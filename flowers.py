# -*- coding: utf-8 -*-
"""Flowers.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TAIN4YRfDcFcuixaZ5y6-DekPVJiWYgY
"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

!pip install -q kaggle
from  google.colab import files
files.upload()

# Install the Kaggle library
!pip install -q kaggle

# Upload your kaggle.json file (you'll be prompted to choose the file)
from google.colab import files
files.upload()

# Create the necessary directory and move the kaggle.json file
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Verify the setup by listing datasets (should show a list if successful)
!kaggle datasets list

# Import the tensorflow module.
import tensorflow as tf

# Check if GPU is available
device_name = tf.test.gpu_device_name()
if device_name == '': #Check for empty string instead of assuming GPU:0.
    print('No GPU found. Using CPU instead.') #Inform that it will use CPU.
else:
    print('Found GPU at: {}'.format(device_name)) # Print GPU name if available.

import os
import zipfile
import pandas as pd

# Define the path to the ZIP file
file_path = '/content/flowers.zip'

# Define the expected CSV file name within the ZIP (if any)
csv_file_name = 'your_csv_file.csv'  # Replace 'your_csv_file.csv' with the actual name

# Open the ZIP file
with zipfile.ZipFile(file_path, 'r') as zip_ref:
    # Check if the expected CSV file exists in the ZIP
    if csv_file_name in zip_ref.namelist():
        # If it exists, extract it to a temporary file
        with zip_ref.open(csv_file_name) as csv_file:
            # Read the CSV file into a Pandas DataFrame
            df = pd.read_csv(csv_file)

        # Now you can work with the DataFrame 'df'
        # ... your code to process the DataFrame ...

        # Extract unique class labels (replace 'Loan_Status' with the actual column name)
        classes = df['Loan_Status'].unique().tolist()
        print(classes)
    else:
        print(f"Error: CSV file '{csv_file_name}' not found in the ZIP archive.")

import pandas as pd

import os
import pandas as pd

# Define the directory to walk (replace with your actual directory path)
DIR = '/content/flowers'  # Example path, adjust as needed

label = []
path = []

for dirname, _, filenames in os.walk(DIR):
    for filename in filenames:
        if os.path.splitext(filename)[-1] == '.png':  # If filename contains .png
            if dirname.split()[-1] != 'GT':
                label.append(os.path.split(dirname)[-1])
                path.append(os.path.join(dirname, filename))

# Create df
df = pd.DataFrame(columns=['path', 'label'])
df['path'] = path
df['label'] = label

df.head()

df.tail()

import pandas as pd
import matplotlib.pyplot as plt # Import the matplotlib.pyplot module and assign it to the alias plt

idx = 0
plt.figure(figsize=(15,12))
for unique_label in df['label'].unique():
    plt.subplot(3, 3, idx+1)
    plt.imshow(plt.imread(df[df['label']==unique_label].iloc[0,0]))
    plt.title(unique_label)
    plt.axis('off')
    idx+=1

import os
import pandas as pd

# 1. Verify and correct the 'DIR' variable
# Make sure 'DIR' points to the correct directory where your images are stored.
# For example, if your images are in '/content/Fish_Dataset/Fish_Dataset', set:
DIR = '/content/flowers.zip'  # Replace with your actual path


label = []
path = []

# 2. Check the file filtering logic
for dirname, _, filenames in os.walk(DIR):
    for filename in filenames:
        # a. Check for various image extensions (e.g., .jpg, .jpeg) if needed
        # b. Review the dirname.split()[-1]!='GT' condition
        #    to ensure it's correctly excluding unwanted directories
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            if 'GT' not in dirname.split(os.sep):  # Use os.sep for platform independence
                label.append(os.path.basename(dirname))  # Use basename for better clarity
                path.append(os.path.join(dirname, filename))

# 3. Ensure DataFrame creation and population are correct
df = pd.DataFrame(columns=['path', 'label'])
df['path'] = path
df['label'] = label

# Print some information about the DataFrame to debug
print(f"Number of images found: {len(df)}")
print(df.head())

import os
import pandas as pd

# 1. Verify and correct the 'DIR' variable
# Make sure 'DIR' points to the correct directory where your images are stored.
# For example, if your images are in '/content/flowers', set:
DIR = '/content/flowers'  # Replace with your actual path

label = []
path = []

# 2. Check the file filtering logic
for dirname, _, filenames in os.walk(DIR):
    for filename in filenames:
        # a. Check for various image extensions (e.g., .jpg, .jpeg) if needed
        # b. Review the dirname.split()[-1]!='GT' condition
        #    to ensure it's correctly excluding unwanted directories
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            if 'GT' not in dirname.split(os.sep):  # Use os.sep for platform independence
                label.append(os.path.basename(dirname))  # Use basename for better clarity
                path.append(os.path.join(dirname, filename))

# 3. Ensure DataFrame creation and population are correct
df = pd.DataFrame(columns=['path', 'label'])
df['path'] = path
df['label'] = label

# Print some information about the DataFrame to debug
print(f"Number of images found: {len(df)}")
print(df.head())

from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_generator = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)
test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)

import os
import pandas as pd

# 1. Verify and correct the 'DIR' variable
# Ensure 'DIR' points to the extracted directory, not the zip file
DIR = '/content/flowers'  # Replace with the actual extracted directory path

label = []
path = []

# 2. Check the file filtering logic
for dirname, _, filenames in os.walk(DIR):
    for filename in filenames:
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            if 'GT' not in dirname.split(os.sep):  # Use os.sep for platform independence
                label.append(os.path.basename(dirname))  # Use basename for better clarity
                path.append(os.path.join(dirname, filename))

# 3. Ensure DataFrame creation and population are correct
df = pd.DataFrame(columns=['path', 'label'])
df['path'] = path
df['label'] = label

# Print some information about the DataFrame to debug
print(f"Number of images found: {len(df)}")
print(df.head())

from tensorflow.keras.applications import MobileNetV2 # Import the MobileNetV2 model

# ... (your existing code for data loading and preprocessing) ...

# Load the pre-trained MobileNetV2 model (example)
pretrained_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# ... (rest of your code) ...

# Now you can save the model:
pretrained_model.save('test_model.h5')

import pandas as pd  # Import the pandas library

# Sample data
data = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}

# Create the DataFrame
df = pd.DataFrame(data)

# Now you can call describe
df.describe()

from tensorflow.keras.models import load_model

# Load the model
model = load_model('/content/test_model.h5')

import os

# Update the image_dir to the actual directory where images are stored
image_dir = '/content/flowers'  # This should be the directory containing images

# Check if the directory exists
if os.path.exists(image_dir):
    # List all files in the directory
    images = os.listdir(image_dir)
    print(f"Found {len(images)} images in the directory.")

    # Check if images are being processed
    if len(images) == 0:
        print("No images found. Please check the directory path.")
    else:
        print(images[:10])  # Print the first 10 image file names
else:
    print(f"Error: Directory '{image_dir}' not found.")

import os

# 1. Verify the directory path
image_dir = '/content/flowers'  # Double-check if this is the correct path

# 2. Print the current working directory for debugging
print("Current working directory:", os.getcwd())

# 3. Check if the directory exists before listing files
if os.path.exists(image_dir):
    # List files in the specified directory
    print("Files in the directory:", os.listdir(image_dir))
else:
    print(f"Error: Directory '{image_dir}' not found. Please check the path.")
    # If the directory is not found, you may need to:
    # - Unzip your data if it's in a zip file
    # - Mount your Google Drive if the data is there
    # - Correct the path if there's a typo

image_dir = r'C:\Users\pathi\Desktop\Fast api\images'



import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# ... (Your existing code to load the model) ...

# 1. Verify the directory path - Make sure it's the extracted folder
test_data_dir = '/content/flowers'  # Update if needed

# 2. Print the directory contents to check if it exists and has the expected structure
import os
print(os.listdir(test_data_dir))

img_height, img_width = 224, 224

# Create a test data generator
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(img_height, img_width),
    batch_size=32,
    class_mode='categorical',  # Or 'binary' if you have only two classes
    shuffle=False
)

# ... (Rest of your code remains the same) ...

import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# ... (Your existing code to load the model) ...

# 1. Verify the directory path - Make sure it's the extracted folder
test_data_dir = '/content/flowers'  # Update if needed

# ----> Check if the directory exists and handle the case where it's not found
if not os.path.exists(test_data_dir):
    print(f"Error: Directory '{test_data_dir}' not found. Please make sure you have extracted the 'flowers' dataset.")
    # You might need to extract the dataset or adjust the path
else:
    # 2. Print the directory contents to check if it exists and has the expected structure
    import os
    print(os.listdir(test_data_dir))

    img_height, img_width = 224, 224

    # Create a test data generator
    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
    test_generator = test_datagen.flow_from_directory(
        test_data_dir,
        target_size=(img_height, img_width),
        batch_size=32,
        class_mode='categorical',  # Or 'binary' if you have only two classes
        shuffle=False
    )

    # Extract test images and labels from the generator
    # Note: This assumes 'x' represents images and 'y' represents labels in the generator
    test_images, test_labels = next(test_generator)

import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# ... (Your existing code to load the model) ...

# 1. Verify the directory path - Make sure it's the extracted folder
test_data_dir = '/content/flowers'  # Update if needed

# ----> Check if the directory exists and handle the case where it's not found
if not os.path.exists(test_data_dir):
    print(f"Error: Directory '{test_data_dir}' not found. Please make sure you have extracted the 'flowers' dataset.")
    # You might need to extract the dataset or adjust the path
else:
    # 2. Print the directory contents to check if it exists and has the expected structure
    import os
    print(os.listdir(test_data_dir))

    img_height, img_width = 224, 224

    # Create a test data generator
    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
    test_generator = test_datagen.flow_from_directory(
        test_data_dir,
        target_size=(img_height, img_width),
        batch_size=32,
        class_mode='categorical',  # Or 'binary' if you have only two classes
        shuffle=False
    )

    # Extract test images and labels from the generator
    # Note: This assumes 'x' represents images and 'y' represents labels in the generator
    test_images, test_labels = next(test_generator)

# Assuming 'model' is your loaded model and 'test_images' are your test images
# ----> Check if test_images is defined before making predictions
if 'test_images' in locals():  # Check if test_images exists in the current scope
    predictions = model.predict(test_images)

    # Convert probabilities into predicted labels
    predicted_labels = predictions.argmax(axis=1)
else:
    print("Error: 'test_images' is not defined. Please check if the image loading process was successful.")

import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.models import load_model

# Load the trained model
model = load_model('test_model.h5')

# 1. Verify the directory path - Make sure it's the extracted folder
test_data_dir = '/content/flowers'  # Update if needed

# ----> Check if the directory exists and handle the case where it's not found
if not os.path.exists(test_data_dir):
    print(f"Error: Directory '{test_data_dir}' not found. Please make sure you have extracted the 'flowers' dataset.")
    # You might need to extract the dataset or adjust the path
else:
    # 2. Print the directory contents to check if it exists and has the expected structure
    import os
    print(os.listdir(test_data_dir))

    img_height, img_width = 224, 224

    # Create a test data generator
    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
    test_generator = test_datagen.flow_from_directory(
        test_data_dir,
        target_size=(img_height, img_width),
        batch_size=32,
        class_mode='categorical',  # Or 'binary' if you have only two classes
        shuffle=False
    )

    # Extract test images and labels from the generator
    # Note: This assumes 'x' represents images and 'y' represents labels in the generator
    test_images, test_labels = next(test_generator)

    # Make predictions on test data # Moved prediction code inside the else block
    predictions = model.predict(test_images)

    # Get the predicted labels (numeric indices)
    predicted_labels = predictions.argmax(axis=1)

    # ----> Assuming you have 'train_generator' defined somewhere, use its class_indices
    # ----> Otherwise, you'll need to define a mapping from class names to indices
    # Check the class-to-index mapping
    print(test_generator.class_indices) # Use test_generator.class_indices

    # Create an inverse mapping from numeric labels back to class names
    inverse_label_map = {v: k for k, v in test_generator.class_indices.items()} # Use test_generator.class_indices

    # Convert the predicted labels to class names
    predicted_class_names = [inverse_label_map.get(label, 'unknown') for label in predicted_labels]

    # Display the predicted class names
    print(predicted_class_names)

import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.models import load_model

# Step 1: Load the model
model = load_model('test_model.h5')

# ----> Define the test data directory and image dimensions
test_data_dir = '/content/flowers'  # Update if needed
img_height, img_width = 224, 224

# ----> Check if the directory exists and handle the case where it's not found
if not os.path.exists(test_data_dir):
    print(f"Error: Directory '{test_data_dir}' not found. Please make sure you have extracted the 'flowers' dataset.")
else:
    # Create a test data generator
    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
    test_generator = test_datagen.flow_from_directory(
        test_data_dir,
        target_size=(img_height, img_width),
        batch_size=32,
        class_mode='categorical',
        shuffle=False
    )

    # Extract test images and labels from the generator
    test_images, test_labels = next(test_generator)


# ----> Now you can safely use test_images for prediction
# Step 2: Make predictions
predictions = model.predict(test_images)

# Step 3: Get the predicted labels
predicted_labels = predictions.argmax(axis=1)

# ----> Get the label mapping from the test generator
label_map = test_generator.class_indices
inverse_label_map = {v: k for k, v in label_map.items()}

# ----> Map predictions to class names using the inverse label map
predicted_class_names = [inverse_label_map.get(label, 'unknown') for label in predicted_labels]

# Step 5: Display predictions
print(predicted_class_names)

!pip install fastapi
!pip install python-multipart # Install the missing python-multipart library
from fastapi import FastAPI, File, UploadFile

app = FastAPI()  # Create a FastAPI app instance

@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    # Your code to process the image
    result = "Some result here"
    return {"prediction": result}